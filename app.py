import streamlit as st
import pandas as pd
import json
import time
from datetime import datetime
import os
from dotenv import load_dotenv
from vanna_setup import initialize_vanna
import mysql.connector
from mysql.connector import Error
import hashlib
from typing import Dict, List, Optional, Set, Tuple, Dict
import re

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½å¤šæ•°æ®åº“æŸ¥è¯¢åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .status-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 15px;
        border-radius: 10px;
        text-align: center;
        margin: 5px;
    }
    .database-card {
        background-color: #f0f7ff;
        border-left: 4px solid #4CAF50;
        padding: 12px;
        margin: 8px 0;
        border-radius: 8px;
    }
    .priority-database-card {
        background-color: #fff3e0;
        border-left: 4px solid #FF9800;
        padding: 12px;
        margin: 8px 0;
        border-radius: 8px;
        border: 2px solid #FF9800;
    }
    .table-card {
        background-color: #f9f9f9;
        border-left: 3px solid #2196F3;
        padding: 10px;
        margin: 5px 0;
        border-radius: 5px;
    }
    .sql-container {
        background-color: #272822;
        color: #f8f8f2;
        padding: 15px;
        border-radius: 8px;
        font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
        margin: 15px 0;
    }
    .result-container {
        border: 2px solid #e3f2fd;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        background-color: #fafafa;
    }
    .progress-container {
        background-color: #e8f5e9;
        border-radius: 10px;
        padding: 15px;
        margin: 15px 0;
    }
    .priority-badge {
        background-color: #FF9800;
        color: white;
        padding: 3px 8px;
        border-radius: 12px;
        font-size: 0.8rem;
        margin-left: 8px;
    }
    .train-tab {
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 10px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–Vanna
@st.cache_resource
def init_vanna():
    try:
        vn = initialize_vanna()
        # åˆå§‹åŒ–è®­ç»ƒå†å²è®°å½•
        if 'train_history' not in st.session_state:
            st.session_state.train_history = []
        return vn
    except Exception as e:
        st.error(f"åˆå§‹åŒ–Vannaå¤±è´¥: {str(e)}")
        return None

# æ™ºèƒ½æ•°æ®åº“ç®¡ç†å™¨
class IntelligentDBAssistant:
    def __init__(self):
        self.connections = {}
        self.discovered_databases = {}
        self.schema_cache = {}

    def get_connection(self, host: str, database: str = None):
        """è·å–æ•°æ®åº“è¿æ¥"""
        key = f"{host}_{database}" if database else host

        if key in self.connections:
            try:
                self.connections[key].ping(reconnect=True)
                return self.connections[key]
            except:
                pass

        try:
            conn = mysql.connector.connect(
                host=host,
                database=database,
                user=os.getenv('DB_USER'),
                password=os.getenv('DB_PASSWORD'),
                port=int(os.getenv('DB_PORT', 3306)),
                charset='utf8mb4',
                connect_timeout=10
            )
            self.connections[key] = conn
            return conn
        except Error as e:
            print(f"è¿æ¥å¤±è´¥ {host}:{database}: {str(e)}")
            return None

    def discover_all_databases(self, host: str) -> Dict:
        """å‘ç°æ‰€æœ‰æ•°æ®åº“å’Œè¡¨"""
        conn = self.get_connection(host)
        if not conn:
            return {}

        try:
            cursor = conn.cursor()
            cursor.execute("SHOW DATABASES")
            databases = [row[0] for row in cursor.fetchall()
                        if row[0] not in ['information_schema', 'mysql', 'performance_schema', 'sys']]

            all_info = {
                'host': host,
                'databases': {},
                'total_databases': 0,
                'total_tables': 0,
                'discovery_time': datetime.now().isoformat()
            }

            total_tables = 0

            for db in databases:
                try:
                    db_conn = self.get_connection(host, db)
                    if db_conn:
                        cursor_db = db_conn.cursor()
                        cursor_db.execute("SHOW TABLES")
                        tables = [row[0] for row in cursor_db.fetchall()]
                        cursor_db.close()

                        if tables:
                            # è·å–æ¯ä¸ªè¡¨çš„å­—æ®µä¿¡æ¯
                            tables_info = {}
                            for table in tables:
                                try:
                                    cursor_desc = db_conn.cursor()
                                    cursor_desc.execute(f"DESCRIBE `{table}`")
                                    columns = cursor_desc.fetchall()
                                    cursor_desc.close()

                                    tables_info[table] = {
                                        'columns': [col[0] for col in columns],
                                        'column_types': [col[1] for col in columns],
                                        'column_count': len(columns)
                                    }
                                except:
                                    tables_info[table] = {'columns': [], 'column_types': [], 'column_count': 0}

                            all_info['databases'][db] = {
                                'tables': tables,
                                'table_count': len(tables),
                                'tables_info': tables_info
                            }
                            total_tables += len(tables)

                except Exception as e:
                    print(f"è·å–æ•°æ®åº“ {db} ä¿¡æ¯å¤±è´¥: {str(e)}")
                    continue

            cursor.close()

            all_info['total_databases'] = len(all_info['databases'])
            all_info['total_tables'] = total_tables

            return all_info

        except Error as e:
            print(f"å‘ç°æ•°æ®åº“å¤±è´¥: {str(e)}")
            return {}

    def get_table_ddl(self, host: str, database: str, table_name: str) -> Optional[str]:
        """è·å–è¡¨DDL"""
        try:
            conn = self.get_connection(host, database)
            if not conn:
                return None

            cursor = conn.cursor()
            cursor.execute(f"SHOW CREATE TABLE `{database}`.`{table_name}`")
            result = cursor.fetchone()
            cursor.close()

            return result[1] if result else None
        except Exception as e:
            print(f"è·å–DDLå¤±è´¥ {database}.{table_name}: {str(e)}")
            return None

    def execute_query(self, host: str, database: str, query: str) -> tuple:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        try:
            conn = self.get_connection(host, database)
            if not conn:
                return None, "è¿æ¥å¤±è´¥"

            cursor = conn.cursor(dictionary=True)
            cursor.execute(query)
            result = cursor.fetchall()
            cursor.close()

            return result, None
        except Error as e:
            return None, str(e)

    def get_table_sample_data(self, host: str, database: str, table_name: str, limit: int = 5) -> Optional[list]:
        """è·å–è¡¨çš„æ ·ä¾‹æ•°æ®"""
        try:
            conn = self.get_connection(host, database)
            if not conn:
                return None

            cursor = conn.cursor(dictionary=True)
            cursor.execute(f"SELECT * FROM `{table_name}` LIMIT {limit}")
            result = cursor.fetchall()
            cursor.close()

            return result
        except Error as e:
            print(f"è·å–æ ·ä¾‹æ•°æ®å¤±è´¥ {database}.{table_name}: {str(e)}")
            return None

# Vannaå®Œæ•´è®­ç»ƒç®¡ç†å™¨
class VannaTrainingManager:
    def __init__(self, vn):
        self.vn = vn
        self.train_history = []

    def add_to_history(self, train_type: str, content: str, metadata: dict = None):
        """æ·»åŠ è®­ç»ƒå†å²"""
        history_item = {
            'type': train_type,
            'content': content[:100] + "..." if len(content) > 100 else content,
            'timestamp': datetime.now().isoformat(),
            'metadata': metadata or {}
        }
        self.train_history.append(history_item)

        # é™åˆ¶å†å²è®°å½•æ•°é‡
        if len(self.train_history) > 50:
            self.train_history = self.train_history[-50:]

    def train_ddl(self, ddl: str, metadata: dict = None) -> bool:
        """è®­ç»ƒDDL"""
        try:
            self.vn.train(ddl=ddl)
            self.add_to_history('DDL', ddl, metadata)
            return True
        except Exception as e:
            st.error(f"DDLè®­ç»ƒå¤±è´¥: {str(e)}")
            return False

    def train_documentation(self, documentation: str, metadata: dict = None) -> bool:
        """è®­ç»ƒæ–‡æ¡£"""
        try:
            self.vn.train(documentation=documentation)
            self.add_to_history('Documentation', documentation, metadata)
            return True
        except Exception as e:
            st.error(f"æ–‡æ¡£è®­ç»ƒå¤±è´¥: {str(e)}")
            return False

    def train_question_sql(self, question: str, sql: str, metadata: dict = None) -> bool:
        """è®­ç»ƒé—®é¢˜-SQLå¯¹"""
        try:
            self.vn.train(question=question, sql=sql)
            self.add_to_history('Question-SQL', f"Q: {question}\nSQL: {sql}", metadata)
            return True
        except Exception as e:
            st.error(f"é—®é¢˜-SQLè®­ç»ƒå¤±è´¥: {str(e)}")
            return False

    def train_plan(self, plan: str, metadata: dict = None) -> bool:
        """è®­ç»ƒæ‰§è¡Œè®¡åˆ’ï¼ˆå¦‚æœæœ‰æ­¤æ–¹æ³•ï¼‰"""
        try:
            if hasattr(self.vn, 'train_plan'):
                self.vn.train_plan(plan=plan)
                self.add_to_history('Plan', plan, metadata)
                return True
            else:
                st.warning("å½“å‰Vannaç‰ˆæœ¬ä¸æ”¯æŒPlanè®­ç»ƒ")
                return False
        except Exception as e:
            st.error(f"Planè®­ç»ƒå¤±è´¥: {str(e)}")
            return False

    def get_train_history(self) -> List[dict]:
        """è·å–è®­ç»ƒå†å²"""
        return self.train_history

    def clear_history(self):
        """æ¸…ç©ºè®­ç»ƒå†å²"""
        self.train_history = []

    def get_training_stats(self) -> dict:
        """è·å–è®­ç»ƒç»Ÿè®¡"""
        stats = {
            'total': len(self.train_history),
            'by_type': {}
        }

        for item in self.train_history:
            train_type = item['type']
            if train_type not in stats['by_type']:
                stats['by_type'][train_type] = 0
            stats['by_type'][train_type] += 1

        return stats

# æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆå™¨ - ä¿®å¤ç‰ˆ
class EnhancedSmartQueryGenerator:
    def __init__(self, vanna_instance):
        self.vn = vanna_instance
        self.trained_items = set()
        self.is_trained = False
        self.priority_databases = set()
        self.training_manager = None

        # åˆå§‹åŒ–è®­ç»ƒç®¡ç†å™¨
        if vanna_instance:
            self.training_manager = VannaTrainingManager(vanna_instance)

    def set_priority_databases(self, databases: Set[str]):
        """è®¾ç½®ä¼˜å…ˆæ•°æ®åº“"""
        self.priority_databases = databases

    def train_all_databases(self, db_manager, host: str, db_info: Dict) -> Dict:
        """ä¸€é”®è®­ç»ƒæ‰€æœ‰æ•°æ®åº“"""
        results = {
            'success': False,
            'databases_trained': 0,
            'tables_trained': 0,
            'errors': [],
            'training_time': None
        }

        if not db_info or 'databases' not in db_info:
            results['errors'].append("æ— æ•°æ®åº“ä¿¡æ¯")
            return results

        start_time = time.time()
        databases = db_info['databases']

        # è¿›åº¦æ˜¾ç¤º
        progress_placeholder = st.empty()
        status_placeholder = st.empty()
        progress_bar = st.progress(0)

        total_dbs = len(databases)
        trained_dbs = 0
        trained_tables = 0

        # å¦‚æœæœ‰ä¼˜å…ˆæ•°æ®åº“ï¼Œå…ˆè®­ç»ƒä¼˜å…ˆæ•°æ®åº“
        training_order = []
        priority_dbs = []
        other_dbs = []

        for db_name in databases.keys():
            if db_name in self.priority_databases:
                priority_dbs.append(db_name)
            else:
                other_dbs.append(db_name)

        training_order = priority_dbs + other_dbs

        for i, db_name in enumerate(training_order):
            db_data = databases[db_name]
            db_progress = (i + 1) / total_dbs
            progress_bar.progress(db_progress)

            # æ˜¾ç¤ºæ˜¯å¦æ˜¯ä¼˜å…ˆæ•°æ®åº“
            priority_mark = "ğŸ¯ " if db_name in self.priority_databases else ""
            status_placeholder.text(f"{priority_mark}æ­£åœ¨è®­ç»ƒæ•°æ®åº“: {db_name} ({i+1}/{total_dbs})")

            tables = db_data.get('tables', [])
            tables_info = db_data.get('tables_info', {})

            for table in tables:
                try:
                    # è®­ç»ƒDDL
                    ddl = db_manager.get_table_ddl(host, db_name, table)
                    if ddl and self.training_manager:
                        metadata = {
                            'database': db_name,
                            'table': table,
                            'priority': db_name in self.priority_databases
                        }
                        self.training_manager.train_ddl(ddl, metadata)

                    # è®­ç»ƒå¤šç§æŸ¥è¯¢æ¨¡å¼
                    if self.training_manager:
                        metadata = {
                            'database': db_name,
                            'table': table,
                            'priority': db_name in self.priority_databases
                        }

                        # 1. è®­ç»ƒç®€å•çš„è¡¨åæŸ¥è¯¢
                        table_query = f"æŸ¥è¯¢è¡¨ {table}"
                        sql = f"SELECT * FROM `{db_name}`.`{table}` LIMIT 10"
                        self.training_manager.train_question_sql(table_query, sql, metadata)

                        # 2. è®­ç»ƒè¡¨è¯¦æƒ…æŸ¥è¯¢
                        table_detail_query = f"æŸ¥çœ‹è¡¨ {table} çš„è¯¦æƒ…"
                        detail_sql = f"DESCRIBE `{db_name}`.`{table}`"
                        self.training_manager.train_question_sql(table_detail_query, detail_sql, metadata)

                        # 3. è®­ç»ƒä¸­æ–‡æŸ¥è¯¢
                        chinese_query = f"å¸®æˆ‘æŸ¥ {table} è¡¨"
                        self.training_manager.train_question_sql(chinese_query, sql, metadata)

                        # 4. è®­ç»ƒè¡¨ç»“æ„æè¿°
                        if table in tables_info:
                            columns = tables_info[table].get('columns', [])
                            column_types = tables_info[table].get('column_types', [])

                            if columns:
                                columns_desc = []
                                for col, col_type in zip(columns, column_types):
                                    columns_desc.append(f"{col} ({col_type})")

                                priority_note = "ï¼ˆä¼˜å…ˆæ•°æ®åº“ï¼‰" if db_name in self.priority_databases else ""
                                table_desc = f"æ•°æ®åº“ {db_name} {priority_note}ä¸­çš„è¡¨ {table} åŒ…å«ä»¥ä¸‹å­—æ®µ: {', '.join(columns_desc)}"
                                self.training_manager.train_documentation(table_desc, metadata)

                    self.trained_items.add(f"{db_name}.{table}")
                    trained_tables += 1

                except Exception as e:
                    results['errors'].append(f"è¡¨ {db_name}.{table} è®­ç»ƒå¤±è´¥: {str(e)}")

            # è®­ç»ƒæ•°æ®åº“ä¸Šä¸‹æ–‡
            try:
                if tables and self.training_manager:
                    metadata = {
                        'database': db_name,
                        'priority': db_name in self.priority_databases
                    }
                    priority_tag = "ï¼ˆä¼˜å…ˆæ•°æ®åº“ï¼‰" if db_name in self.priority_databases else ""
                    db_context = f"æ•°æ®åº“ {db_name} {priority_tag}åŒ…å«ä»¥ä¸‹è¡¨: {', '.join(tables[:10])}"
                    if len(tables) > 10:
                        db_context += f" ç­‰å…± {len(tables)} ä¸ªè¡¨"
                    self.training_manager.train_documentation(db_context, metadata)

                trained_dbs += 1

            except Exception as e:
                results['errors'].append(f"æ•°æ®åº“ {db_name} ä¸Šä¸‹æ–‡è®­ç»ƒå¤±è´¥: {str(e)}")

        progress_bar.empty()
        status_placeholder.empty()

        results['success'] = True
        results['databases_trained'] = trained_dbs
        results['tables_trained'] = trained_tables
        results['training_time'] = time.time() - start_time
        self.is_trained = True

        return results

    def generate_smart_query(self, user_query: str, db_info: Dict) -> Dict:
        """æ™ºèƒ½ç”ŸæˆæŸ¥è¯¢"""
        try:
            # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…è¡¨å
            exact_match_result = self._try_exact_table_match(user_query, db_info)
            if exact_match_result:
                return exact_match_result

            # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨Vannaæ™ºèƒ½æŸ¥è¯¢
            sql = self.vn.generate_sql(question=user_query)

            if not sql:
                return {'success': False, 'error': 'æ— æ³•ç”ŸæˆSQL'}

            # åˆ†æSQLä¸­ä½¿ç”¨äº†å“ªäº›æ•°æ®åº“
            used_databases = self._analyze_sql_databases(sql, db_info)

            return {
                'success': True,
                'sql': sql,
                'enhanced_query': user_query,
                'relevant_info': {'databases': {}, 'total_matches': 0},
                'keywords': [],
                'used_databases': used_databases,
                'priority_used': any(db in self.priority_databases for db in used_databases),
                'match_type': 'vanna_generated'
            }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _try_exact_table_match(self, user_query: str, db_info: Dict) -> Optional[Dict]:
        """å°è¯•ç²¾ç¡®åŒ¹é…è¡¨å"""
        if not db_info or 'databases' not in db_info:
            return None

        # ä»æŸ¥è¯¢ä¸­æå–å¯èƒ½çš„è¡¨å
        potential_table_names = self._extract_table_names_from_query(user_query)

        if not potential_table_names:
            return None

        # é¦–å…ˆåœ¨ä¼˜å…ˆæ•°æ®åº“ä¸­æŸ¥æ‰¾
        for table_name in potential_table_names:
            for db_name in self.priority_databases:
                if db_name in db_info['databases']:
                    db_data = db_info['databases'][db_name]
                    tables = db_data.get('tables', [])

                    # ç²¾ç¡®åŒ¹é…
                    if table_name in tables:
                        return self._create_exact_match_result(db_name, table_name, user_query)

                    # å¿½ç•¥å¤§å°å†™åŒ¹é…
                    for actual_table in tables:
                        if actual_table.lower() == table_name.lower():
                            return self._create_exact_match_result(db_name, actual_table, user_query)

        # ç„¶ååœ¨æ‰€æœ‰æ•°æ®åº“ä¸­æŸ¥æ‰¾
        for table_name in potential_table_names:
            for db_name, db_data in db_info['databases'].items():
                tables = db_data.get('tables', [])

                # ç²¾ç¡®åŒ¹é…
                if table_name in tables:
                    return self._create_exact_match_result(db_name, table_name, user_query)

                # å¿½ç•¥å¤§å°å†™åŒ¹é…
                for actual_table in tables:
                    if actual_table.lower() == table_name.lower():
                        return self._create_exact_match_result(db_name, actual_table, user_query)

        return None

    def _extract_table_names_from_query(self, query: str) -> List[str]:
        """ä»æŸ¥è¯¢ä¸­æå–å¯èƒ½çš„è¡¨å"""
        query_lower = query.lower()

        # å¸¸è§è¡¨åæ¨¡å¼åŒ¹é…
        table_patterns = [
            r'æŸ¥\s+(\w+)\s*è¡¨',    # "æŸ¥ xxx è¡¨"
            r'æŸ¥è¯¢\s+(\w+)\s*è¡¨',   # "æŸ¥è¯¢ xxx è¡¨"
            r'è¡¨\s+(\w+)',         # "è¡¨ xxx"
            r'\b(\w+)\bè¡¨',        # "xxxè¡¨"
            r'å¸®æˆ‘æŸ¥\s+(\w+)',     # "å¸®æˆ‘æŸ¥ xxx"
        ]

        potential_table_names = []

        for pattern in table_patterns:
            matches = re.findall(pattern, query_lower)
            potential_table_names.extend(matches)

        # æå–å•è¯
        words = re.findall(r'\b(\w+)\b', query_lower)
        for word in words:
            if len(word) >= 3 and word not in ['æŸ¥è¯¢', 'å¸®æˆ‘', 'è¯¦æƒ…', 'æŸ¥çœ‹']:
                potential_table_names.append(word)

        # å»é‡
        potential_table_names = list(set(potential_table_names))

        return potential_table_names

    def _create_exact_match_result(self, db_name: str, table_name: str, user_query: str) -> Dict:
        """åˆ›å»ºç²¾ç¡®åŒ¹é…çš„ç»“æœ"""
        # æ ¹æ®æŸ¥è¯¢æ„å›¾ç”ŸæˆSQL
        sql = self._generate_query_by_intent(db_name, table_name, user_query)

        return {
            'success': True,
            'sql': sql,
            'enhanced_query': f"æŸ¥è¯¢è¡¨ {db_name}.{table_name}",
            'relevant_info': {
                'databases': {
                    db_name: {
                        'tables': {
                            table_name: {'matches': ['ç²¾ç¡®åŒ¹é…']}
                        },
                        'priority': db_name in self.priority_databases
                    }
                },
                'total_matches': 1
            },
            'keywords': [table_name],
            'used_databases': [db_name],
            'priority_used': db_name in self.priority_databases,
            'match_type': 'exact_table'
        }

    def _generate_query_by_intent(self, db_name: str, table_name: str, user_query: str) -> str:
        """æ ¹æ®æŸ¥è¯¢æ„å›¾ç”ŸæˆSQL"""
        query_lower = user_query.lower()

        if any(word in query_lower for word in ['è¯¦æƒ…', 'ç»“æ„', 'å­—æ®µ', 'åˆ—', 'desc', 'describe']):
            return f"DESCRIBE `{db_name}`.`{table_name}`;"
        elif any(word in query_lower for word in ['æ•°é‡', 'è®¡æ•°', 'count', 'å¤šå°‘']):
            return f"SELECT COUNT(*) FROM `{db_name}`.`{table_name}`;"
        else:
            return f"SELECT * FROM `{db_name}`.`{table_name}` LIMIT 10;"

    def _analyze_sql_databases(self, sql: str, db_info: Dict) -> List[str]:
        """åˆ†æSQLä¸­ä½¿ç”¨çš„æ•°æ®åº“"""
        used_dbs = []

        pattern = r'`?(\w+)`?\.`?(\w+)`?'
        matches = re.findall(pattern, sql)

        for db_match, _ in matches:
            if db_match in db_info.get('databases', {}):
                used_dbs.append(db_match)

        return used_dbs

def generate_diverse_qsql_pairs(tables_info, pair_count, diversity_level, training_manager):
    """ç”Ÿæˆå¤šæ ·åŒ–çš„é—®é¢˜-SQLå¯¹"""
    try:
        from openai import OpenAI
        import os

        # å‡†å¤‡è¡¨ä¿¡æ¯æ–‡æœ¬
        tables_text = ""
        for table_info in tables_info:
            db_name = table_info['database']
            table_name = table_info['table']
            columns = table_info.get('columns', [])
            columns_info = table_info.get('columns_info', [])

            tables_text += f"æ•°æ®åº“: {db_name}\n"
            tables_text += f"è¡¨: {table_name}\n"
            tables_text += f"å­—æ®µ ({len(columns)}ä¸ª): {', '.join(columns_info)}\n\n"

        # æ„å»ºPrompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªSQLä¸“å®¶ï¼Œéœ€è¦ä¸ºä»¥ä¸‹æ•°æ®åº“è¡¨ç”Ÿæˆè‡ªç„¶è¯­è¨€é—®é¢˜å’Œå¯¹åº”çš„SQLæŸ¥è¯¢å¯¹ã€‚

        è¡¨ä¿¡æ¯ï¼š
        {tables_text}

        è¯·ç”Ÿæˆ{pair_count}ä¸ªå¤šæ ·åŒ–çš„é—®é¢˜-SQLå¯¹ï¼Œæ¶µç›–ä»¥ä¸‹ç±»å‹ï¼š
        1. ç®€å•æŸ¥è¯¢ï¼ˆSELECT *ï¼‰
        2. è¡¨ç»“æ„æŸ¥è¯¢ï¼ˆDESCRIBE/SHOW COLUMNSï¼‰
        3. ç»Ÿè®¡æŸ¥è¯¢ï¼ˆCOUNT, SUM, AVGç­‰ï¼‰
        4. æ¡ä»¶æŸ¥è¯¢ï¼ˆWHEREå­å¥ï¼‰
        5. æ’åºæŸ¥è¯¢ï¼ˆORDER BYï¼‰
        6. åˆ†ç»„æŸ¥è¯¢ï¼ˆGROUP BYï¼‰
        7. å¤šè¡¨æŸ¥è¯¢ï¼ˆJOINï¼Œå¦‚æœæ¶‰åŠå¤šä¸ªè¡¨ï¼‰
        8. å­—æ®µè¯¦æƒ…æŸ¥è¯¢

        å¤šæ ·æ€§è¦æ±‚ï¼š{diversity_level}çº§åˆ«

        æ ¼å¼è¦æ±‚ï¼šæ¯ä¸ªå¯¹å ä¸€è¡Œï¼Œé—®é¢˜å’ŒSQLä¹‹é—´ç”¨"###"åˆ†éš”

        ç¤ºä¾‹ï¼š
        æŸ¥è¯¢ç”¨æˆ·è¡¨çš„æ‰€æœ‰æ•°æ®###SELECT * FROM users LIMIT 10
        æŸ¥çœ‹è®¢å•è¡¨çš„å­—æ®µä¿¡æ¯###DESCRIBE orders
        ç»Ÿè®¡ç”¨æˆ·æ•°é‡###SELECT COUNT(*) FROM users

        ç°åœ¨å¼€å§‹ç”Ÿæˆï¼š"""

        # ä½¿ç”¨.envé…ç½®æ–‡ä»¶ä¸­çš„é˜¿é‡Œäº‘APIé…ç½®
        api_key = os.getenv('ALI_API_KEY')
        base_url = os.getenv('ALI_BASE_URL')
        model = os.getenv('VANNA_MODEL', 'qwen3-max')

        if not api_key:
            st.error("âŒ æœªé…ç½®é˜¿é‡Œäº‘APIå¯†é’¥ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®ALI_API_KEY")
            return []

        # è°ƒç”¨é˜¿é‡Œäº‘API
        client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„SQLæŸ¥è¯¢ç”ŸæˆåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7 if diversity_level == "é«˜" else 0.5,
            max_tokens=2000
        )

        # è§£æå“åº”
        content = response.choices[0].message.content
        lines = content.strip().split('\n')

        pairs = []
        for line in lines:
            line = line.strip()
            if '###' in line:
                question, sql = line.split('###', 1)
                question = question.strip()
                sql = sql.strip()

                # éªŒè¯SQLè¯­æ³•
                if sql.upper().startswith(('SELECT', 'DESCRIBE', 'SHOW', 'COUNT', 'SUM', 'AVG', 'MIN', 'MAX')):
                    pairs.append((question, sql))

        # å¦‚æœAIç”Ÿæˆçš„ä¸å¤Ÿï¼Œè¡¥å……ä¸€äº›åŸºç¡€æŸ¥è¯¢
        if len(pairs) < pair_count:
            for table_info in tables_info:
                db_name = table_info['database']
                table_name = table_info['table']
                columns = table_info.get('columns', [])

                # åŸºç¡€æŸ¥è¯¢
                base_queries = [
                    (f"æŸ¥è¯¢{table_name}è¡¨çš„æ‰€æœ‰æ•°æ®", f"SELECT * FROM `{db_name}`.`{table_name}` LIMIT 10"),
                    (f"æŸ¥çœ‹{table_name}è¡¨çš„å­—æ®µä¿¡æ¯", f"DESCRIBE `{db_name}`.`{table_name}`"),
                    (f"ç»Ÿè®¡{table_name}è¡¨æœ‰å¤šå°‘æ¡è®°å½•", f"SELECT COUNT(*) FROM `{db_name}`.`{table_name}`"),
                ]

                # å¦‚æœæœ‰å­—æ®µï¼Œç”Ÿæˆä¸€äº›å­—æ®µç›¸å…³çš„æŸ¥è¯¢
                if columns:
                    for column in columns[:3]:  # å–å‰3ä¸ªå­—æ®µ
                        base_queries.append(
                            (f"æŸ¥è¯¢{table_name}è¡¨çš„{column}å­—æ®µ", f"SELECT {column} FROM `{db_name}`.`{table_name}` LIMIT 10")
                        )

                pairs.extend(base_queries)

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_pairs = []
        seen = set()
        for question, sql in pairs:
            if (question, sql) not in seen and len(unique_pairs) < pair_count:
                seen.add((question, sql))
                unique_pairs.append((question, sql))

        return unique_pairs

    except ImportError:
        st.error("âŒ æœªå®‰è£…openaiåº“ï¼Œè¯·è¿è¡Œ: pip install openai")
        return []
    except Exception as e:
        print(f"ç”Ÿæˆé—®é¢˜-SQLå¯¹å¤±è´¥: {str(e)}")

        # å¤‡é€‰æ–¹æ¡ˆï¼šç”ŸæˆåŸºç¡€æŸ¥è¯¢
        backup_pairs = []
        for table_info in tables_info[:3]:  # æœ€å¤š3ä¸ªè¡¨
            db_name = table_info['database']
            table_name = table_info['table']
            columns = table_info.get('columns', [])

            # åŸºç¡€æŸ¥è¯¢
            backup_pairs.extend([
                (f"æŸ¥è¯¢{table_name}è¡¨çš„æ‰€æœ‰æ•°æ®", f"SELECT * FROM `{db_name}`.`{table_name}` LIMIT 10"),
                (f"æŸ¥çœ‹{table_name}è¡¨çš„å­—æ®µä¿¡æ¯", f"DESCRIBE `{db_name}`.`{table_name}`"),
                (f"ç»Ÿè®¡{table_name}è¡¨æœ‰å¤šå°‘æ¡è®°å½•", f"SELECT COUNT(*) FROM `{db_name}`.`{table_name}`"),
                (f"ä»{table_name}è¡¨æŸ¥è¯¢å‰10æ¡æ•°æ®", f"SELECT * FROM `{db_name}`.`{table_name}` LIMIT 10"),
            ])

            # å­—æ®µæŸ¥è¯¢
            if columns:
                for column in columns[:2]:
                    backup_pairs.append(
                        (f"æŸ¥è¯¢{table_name}è¡¨çš„{column}å­—æ®µ", f"SELECT {column} FROM `{db_name}`.`{table_name}` LIMIT 10")
                    )

        # é™åˆ¶æ•°é‡
        return backup_pairs[:pair_count]

# æ‰‹åŠ¨è®­ç»ƒç•Œé¢
def show_manual_training_interface(training_manager, db_manager, host, db_info):
    """æ˜¾ç¤ºæ‰‹åŠ¨è®­ç»ƒç•Œé¢"""
    st.markdown("### ğŸ“ æ‰‹åŠ¨è®­ç»ƒ")
    st.info("é€šè¿‡æ‰‹åŠ¨è®­ç»ƒå¯ä»¥å¢å¼ºæ¨¡å‹çš„æŸ¥è¯¢èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤æ‚çš„æŸ¥è¯¢åœºæ™¯")

    # è®­ç»ƒç±»å‹é€‰æ‹©
    train_type = st.selectbox(
        "é€‰æ‹©è®­ç»ƒç±»å‹",
        ["DDLè®­ç»ƒ", "æ–‡æ¡£è®­ç»ƒ", "é—®é¢˜-SQLå¯¹è®­ç»ƒ", "æ‰¹é‡è®­ç»ƒ", "è®­ç»ƒå†å²"],
        key="train_type_select"
    )

    if train_type == "DDLè®­ç»ƒ":
        st.markdown("#### ğŸ“‹ DDLè®­ç»ƒ")
        st.caption("è®­ç»ƒè¡¨çš„åˆ›å»ºè¯­å¥ï¼Œå¸®åŠ©æ¨¡å‹ç†è§£è¡¨ç»“æ„")

        col1, col2 = st.columns([2, 1])

        with col1:
            # é€‰æ‹©æ•°æ®åº“å’Œè¡¨
            if db_info and 'databases' in db_info:
                databases = list(db_info['databases'].keys())
                selected_db = st.selectbox("é€‰æ‹©æ•°æ®åº“", databases)

                if selected_db:
                    tables = db_info['databases'][selected_db]['tables']
                    selected_table = st.selectbox("é€‰æ‹©è¡¨", tables)

                    if st.button("è·å–DDL", key="get_ddl_btn"):
                        with st.spinner("æ­£åœ¨è·å–DDL..."):
                            ddl = db_manager.get_table_ddl(host, selected_db, selected_table)
                            if ddl:
                                st.code(ddl, language="sql")
                                st.session_state.ddl_content = ddl
                                st.session_state.ddl_metadata = {
                                    'database': selected_db,
                                    'table': selected_table
                                }
                            else:
                                st.error("è·å–DDLå¤±è´¥")

        with col2:
            # DDLè¾“å…¥
            ddl_input = st.text_area(
                "æˆ–ç›´æ¥è¾“å…¥DDL",
                value=st.session_state.get('ddl_content', ''),
                height=200,
                placeholder="CREATE TABLE ..."
            )

            metadata = st.session_state.get('ddl_metadata', {})

            if st.button("è®­ç»ƒDDL", type="primary", key="train_ddl_btn"):
                if ddl_input:
                    with st.spinner("æ­£åœ¨è®­ç»ƒ..."):
                        success = training_manager.train_ddl(ddl_input, metadata)
                        if success:
                            st.success("âœ… DDLè®­ç»ƒæˆåŠŸ")
                else:
                    st.warning("è¯·è¾“å…¥DDLå†…å®¹")

    elif train_type == "æ–‡æ¡£è®­ç»ƒ":
        st.markdown("#### ğŸ“ æ–‡æ¡£è®­ç»ƒ")
        st.caption("è®­ç»ƒå…³äºè¡¨ã€å­—æ®µæˆ–ä¸šåŠ¡é€»è¾‘çš„æè¿°æ–‡æ¡£")

        col1, col2 = st.columns([1, 2])

        with col1:
            doc_type = st.selectbox(
                "æ–‡æ¡£ç±»å‹",
                ["è¡¨æè¿°", "å­—æ®µæè¿°", "ä¸šåŠ¡é€»è¾‘", "è‡ªå®šä¹‰"],
                key="doc_type_select"
            )

            # å¦‚æœæ˜¯è¡¨æè¿°ï¼Œå¯ä»¥é€‰æ‹©è¡¨
            if doc_type == "è¡¨æè¿°" and db_info and 'databases' in db_info:
                databases = list(db_info['databases'].keys())
                selected_db = st.selectbox("é€‰æ‹©æ•°æ®åº“", databases, key="doc_db_select")

                if selected_db:
                    tables = db_info['databases'][selected_db]['tables']
                    selected_table = st.selectbox("é€‰æ‹©è¡¨", tables, key="doc_table_select")
                    st.session_state.doc_metadata = {
                        'database': selected_db,
                        'table': selected_table,
                        'type': doc_type
                    }

        with col2:
            documentation = st.text_area(
                "æ–‡æ¡£å†…å®¹",
                height=150,
                placeholder="ä¾‹å¦‚ï¼šç”¨æˆ·è¡¨å­˜å‚¨ç³»ç»Ÿç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…å«ç”¨æˆ·åã€é‚®ç®±ã€åˆ›å»ºæ—¶é—´ç­‰å­—æ®µ..."
            )

            if st.button("è®­ç»ƒæ–‡æ¡£", type="primary", key="train_doc_btn"):
                if documentation:
                    metadata = st.session_state.get('doc_metadata', {'type': doc_type})
                    with st.spinner("æ­£åœ¨è®­ç»ƒ..."):
                        success = training_manager.train_documentation(documentation, metadata)
                        if success:
                            st.success("âœ… æ–‡æ¡£è®­ç»ƒæˆåŠŸ")
                else:
                    st.warning("è¯·è¾“å…¥æ–‡æ¡£å†…å®¹")

    elif train_type == "é—®é¢˜-SQLå¯¹è®­ç»ƒ":
        st.markdown("#### ğŸ’¬ é—®é¢˜-SQLå¯¹è®­ç»ƒ")
        st.caption("è®­ç»ƒè‡ªç„¶è¯­è¨€é—®é¢˜åˆ°SQLçš„æ˜ å°„ï¼Œè¿™æ˜¯æœ€é‡è¦çš„è®­ç»ƒæ–¹å¼")

        # åˆå§‹åŒ–session state
        if 'generated_question' not in st.session_state:
            st.session_state.generated_question = ""
        if 'generated_sql' not in st.session_state:
            st.session_state.generated_sql = ""
        if 'generated_pairs' not in st.session_state:
            st.session_state.generated_pairs = []
        if 'selected_pairs' not in st.session_state:
            st.session_state.selected_pairs = []

        # åˆ›å»ºä¸¤ä¸ªä¸»è¦åŒºåŸŸ
        tab1, tab2 = st.tabs(["ğŸ”§ æ‰‹åŠ¨è®­ç»ƒ", "ğŸ¤– æ™ºèƒ½æ‰¹é‡ç”Ÿæˆ"])

        with tab1:
            # åŸæœ‰çš„æ‰‹åŠ¨è®­ç»ƒç•Œé¢
            col1, col2 = st.columns(2)

            with col1:
                # é—®é¢˜è¾“å…¥æ¡†
                question_container = st.empty()

                if st.session_state.generated_question:
                    question = question_container.text_area(
                        "è‡ªç„¶è¯­è¨€é—®é¢˜",
                        value=st.session_state.generated_question,
                        height=100,
                        placeholder="ä¾‹å¦‚ï¼šæŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·çš„ä¿¡æ¯",
                        key="question_input_with_value"
                    )
                else:
                    question = question_container.text_area(
                        "è‡ªç„¶è¯­è¨€é—®é¢˜",
                        height=100,
                        placeholder="ä¾‹å¦‚ï¼šæŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·çš„ä¿¡æ¯",
                        key="question_input"
                    )

                # ç®€å•çš„é—®é¢˜ç”ŸæˆåŠ©æ‰‹
                if db_info and 'databases' in db_info:
                    with st.expander("ğŸ’¡ ç®€å•ç¤ºä¾‹ç”Ÿæˆ"):
                        databases = list(db_info['databases'].keys())
                        selected_db = st.selectbox("æ•°æ®åº“", databases, key="simple_db_select")

                        if selected_db:
                            tables = db_info['databases'][selected_db]['tables']
                            selected_table = st.selectbox("è¡¨", tables, key="simple_table_select")

                            if st.button("ç”Ÿæˆç®€å•ç¤ºä¾‹", key="simple_gen_btn"):
                                # ç”Ÿæˆå‡ ä¸ªç®€å•çš„ç¤ºä¾‹
                                examples = [
                                    (f"æŸ¥è¯¢{selected_table}è¡¨çš„æ‰€æœ‰æ•°æ®",
                                     f"SELECT * FROM `{selected_db}`.`{selected_table}` LIMIT 10"),
                                    (f"æŸ¥çœ‹{selected_table}è¡¨çš„å­—æ®µä¿¡æ¯",
                                     f"DESCRIBE `{selected_db}`.`{selected_table}`"),
                                    (f"ç»Ÿè®¡{selected_table}è¡¨æœ‰å¤šå°‘æ¡è®°å½•",
                                     f"SELECT COUNT(*) FROM `{selected_db}`.`{selected_table}`"),
                                ]
                                st.session_state.generated_pairs = examples
                                st.rerun()

            with col2:
                # SQLè¾“å…¥æ¡†
                sql_container = st.empty()

                if st.session_state.generated_sql:
                    sql_query = sql_container.text_area(
                        "å¯¹åº”çš„SQL",
                        value=st.session_state.generated_sql,
                        height=100,
                        placeholder="ä¾‹å¦‚ï¼šSELECT * FROM users",
                        key="sql_input_with_value"
                    )
                else:
                    sql_query = sql_container.text_area(
                        "å¯¹åº”çš„SQL",
                        height=100,
                        placeholder="ä¾‹å¦‚ï¼šSELECT * FROM users",
                        key="sql_input"
                    )

                metadata = st.session_state.get('train_metadata', {})

                # ç¡®å®šä½¿ç”¨å“ªä¸ªé—®é¢˜å’ŒSQL
                if st.session_state.generated_question:
                    current_question = st.session_state.generated_question
                else:
                    current_question = question if 'question' in locals() else ""

                if st.session_state.generated_sql:
                    current_sql = st.session_state.generated_sql
                else:
                    current_sql = sql_query if 'sql_query' in locals() else ""

                # å•å¯¹è®­ç»ƒæŒ‰é’®
                if st.button("è®­ç»ƒæ­¤é—®é¢˜-SQLå¯¹", type="primary", key="train_single_btn"):
                    if current_question and current_sql:
                        with st.spinner("æ­£åœ¨è®­ç»ƒ..."):
                            success = training_manager.train_question_sql(current_question, current_sql, metadata)
                            if success:
                                st.success("âœ… é—®é¢˜-SQLå¯¹è®­ç»ƒæˆåŠŸ")
                                # æ¸…ç©ºç”Ÿæˆçš„å†…å®¹
                                st.session_state.generated_question = ""
                                st.session_state.generated_sql = ""
                                st.rerun()
                    else:
                        st.warning("è¯·åŒæ—¶è¾“å…¥é—®é¢˜å’ŒSQL")

        with tab2:
            st.markdown("#### ğŸ¤– æ™ºèƒ½æ‰¹é‡ç”Ÿæˆ")
            st.info("é€‰æ‹©æ•°æ®åº“å’Œè¡¨ï¼Œè®©AIç”Ÿæˆå¤šæ ·åŒ–çš„é—®é¢˜-SQLå¯¹è¿›è¡Œæ‰¹é‡è®­ç»ƒ")

            # æ•°æ®åº“å’Œè¡¨é€‰æ‹©
            if db_info and 'databases' in db_info:
                col_select1, col_select2, col_select3 = st.columns([2, 2, 1])

                with col_select1:
                    # å¤šé€‰æ•°æ®åº“
                    all_databases = list(db_info['databases'].keys())
                    selected_dbs = st.multiselect(
                        "é€‰æ‹©æ•°æ®åº“ï¼ˆå¯å¤šé€‰ï¼‰",
                        all_databases,
                        default=all_databases[:2] if len(all_databases) >= 2 else all_databases,
                        help="é€‰æ‹©è¦ç”Ÿæˆè®­ç»ƒæ•°æ®çš„æ•°æ®åº“"
                    )

                with col_select2:
                    # æ˜¾ç¤ºé€‰ä¸­çš„æ•°æ®åº“ä¸­çš„è¡¨
                    available_tables = []
                    if selected_dbs:
                        for db in selected_dbs:
                            tables = db_info['databases'][db]['tables']
                            for table in tables:
                                available_tables.append(f"{db}.{table}")

                    selected_tables_full = st.multiselect(
                        "é€‰æ‹©è¡¨ï¼ˆå¯å¤šé€‰ï¼‰",
                        available_tables,
                        help="é€‰æ‹©è¦ç”Ÿæˆè®­ç»ƒæ•°æ®çš„è¡¨"
                    )

                    # è§£ææ•°æ®åº“å’Œè¡¨å
                    selected_tables = []
                    table_info_map = {}
                    for table_full in selected_tables_full:
                        if '.' in table_full:
                            db_name, table_name = table_full.split('.', 1)
                            selected_tables.append((db_name, table_name))
                            # è·å–è¡¨ä¿¡æ¯
                            if db_name in db_info['databases'] and table_name in db_info['databases'][db_name]['tables_info']:
                                table_info = db_info['databases'][db_name]['tables_info'][table_name]
                                columns = table_info.get('columns', [])
                                table_info_map[f"{db_name}.{table_name}"] = {
                                    'database': db_name,
                                    'table': table_name,
                                    'columns': columns,
                                    'column_count': len(columns)
                                }

                with col_select3:
                    # ç”Ÿæˆæ•°é‡
                    pair_count = st.number_input("ç”Ÿæˆæ•°é‡", min_value=5, max_value=50, value=15, step=5)

                    # å¤šæ ·æ€§çº§åˆ«
                    diversity = st.select_slider(
                        "å¤šæ ·æ€§çº§åˆ«",
                        options=["ä½", "ä¸­", "é«˜"],
                        value="ä¸­",
                        help="é«˜å¤šæ ·æ€§ä¼šç”Ÿæˆæ›´å¤šç±»å‹çš„æŸ¥è¯¢"
                    )

                # ç”ŸæˆæŒ‰é’®
                if st.button("ğŸ¯ å¼€å§‹æ™ºèƒ½ç”Ÿæˆ", type="primary", use_container_width=True):
                    if not selected_tables:
                        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè¡¨")
                    else:
                        with st.spinner("ğŸ¤– AIæ­£åœ¨ç”Ÿæˆå¤šæ ·åŒ–çš„é—®é¢˜-SQLå¯¹..."):
                            # å‡†å¤‡è¡¨ä¿¡æ¯
                            tables_info = []
                            for db_name, table_name in selected_tables:
                                if db_name in db_info['databases']:
                                    db_data = db_info['databases'][db_name]
                                    if table_name in db_data['tables_info']:
                                        table_info = db_data['tables_info'][table_name]
                                        columns = table_info.get('columns', [])
                                        columns_info = []
                                        for i, col in enumerate(columns):
                                            col_type = table_info.get('column_types', [])[i] if i < len(table_info.get('column_types', [])) else "æœªçŸ¥ç±»å‹"
                                            columns_info.append(f"{col} ({col_type})")

                                        tables_info.append({
                                            'database': db_name,
                                            'table': table_name,
                                            'columns': columns,
                                            'columns_info': columns_info,
                                            'column_count': len(columns)
                                        })

                            # ç”Ÿæˆå¤šæ ·åŒ–çš„é—®é¢˜-SQLå¯¹
                            generated_pairs = generate_diverse_qsql_pairs(
                                tables_info,
                                pair_count,
                                diversity,
                                training_manager
                            )

                            if generated_pairs:
                                st.session_state.generated_pairs = generated_pairs
                                st.session_state.selected_pairs = [True] * len(generated_pairs)  # é»˜è®¤å…¨é€‰
                                st.success(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_pairs)} ä¸ªé—®é¢˜-SQLå¯¹")
                                st.rerun()
                            else:
                                st.error("ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")

                # æ˜¾ç¤ºç”Ÿæˆçš„è®­ç»ƒå¯¹
                if st.session_state.generated_pairs:
                    st.markdown("---")
                    st.markdown(f"#### ğŸ“‹ ç”Ÿæˆç»“æœ ({len(st.session_state.generated_pairs)} å¯¹)")

                    # æ‰¹é‡æ“ä½œ
                    col_batch1, col_batch2, col_batch3 = st.columns(3)
                    with col_batch1:
                        if st.button("âœ… å…¨é€‰", use_container_width=True):
                            st.session_state.selected_pairs = [True] * len(st.session_state.generated_pairs)
                            st.rerun()

                    with col_batch2:
                        if st.button("âŒ å…¨ä¸é€‰", use_container_width=True):
                            st.session_state.selected_pairs = [False] * len(st.session_state.generated_pairs)
                            st.rerun()

                    with col_batch3:
                        if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", use_container_width=True):
                            st.session_state.generated_pairs = []
                            st.session_state.selected_pairs = []
                            st.rerun()

                    # æ˜¾ç¤ºæ‰€æœ‰ç”Ÿæˆçš„å¯¹
                    for idx, (question, sql) in enumerate(st.session_state.generated_pairs):
                        with st.expander(f"ç¬¬ {idx+1} å¯¹: {question[:50]}...", expanded=False):
                            col_display1, col_display2, col_display3 = st.columns([4, 1, 1])

                            with col_display1:
                                st.markdown(f"**é—®é¢˜**: {question}")
                                st.code(sql, language="sql")

                            with col_display2:
                                # ç¼–è¾‘æŒ‰é’®
                                if st.button("âœï¸ ç¼–è¾‘", key=f"edit_{idx}"):
                                    st.session_state.editing_idx = idx
                                    st.session_state.editing_question = question
                                    st.session_state.editing_sql = sql
                                    st.rerun()

                            with col_display3:
                                # é€‰æ‹©æ¡†
                                selected = st.checkbox(
                                    "é€‰æ‹©è®­ç»ƒ",
                                    value=st.session_state.selected_pairs[idx] if idx < len(st.session_state.selected_pairs) else True,
                                    key=f"select_{idx}"
                                )
                                if idx < len(st.session_state.selected_pairs):
                                    st.session_state.selected_pairs[idx] = selected

                    # æ‰¹é‡è®­ç»ƒæŒ‰é’®
                    if st.button("ğŸš€ æ‰¹é‡è®­ç»ƒé€‰ä¸­çš„å¯¹", type="primary", use_container_width=True):
                        selected_count = sum(st.session_state.selected_pairs)
                        if selected_count == 0:
                            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€å¯¹è¿›è¡Œè®­ç»ƒ")
                        else:
                            success_count = 0
                            progress_bar = st.progress(0)
                            status_text = st.empty()

                            for i, selected in enumerate(st.session_state.selected_pairs):
                                if selected and i < len(st.session_state.generated_pairs):
                                    question, sql = st.session_state.generated_pairs[i]
                                    status_text.text(f"æ­£åœ¨è®­ç»ƒç¬¬ {i+1}/{selected_count} å¯¹...")
                                    progress_bar.progress((i + 1) / selected_count)

                                    metadata = {
                                        'database': 'auto_generated',
                                        'table': 'multiple',
                                        'batch_idx': i
                                    }
                                    if training_manager.train_question_sql(question, sql, metadata):
                                        success_count += 1

                            progress_bar.empty()
                            status_text.empty()

                            if success_count > 0:
                                st.success(f"âœ… æ‰¹é‡è®­ç»ƒå®Œæˆï¼æˆåŠŸè®­ç»ƒ {success_count}/{selected_count} å¯¹")
                                # ä¿ç•™æœªé€‰ä¸­çš„å¯¹
                                new_pairs = []
                                new_selected = []
                                for i, selected in enumerate(st.session_state.selected_pairs):
                                    if not selected and i < len(st.session_state.generated_pairs):
                                        new_pairs.append(st.session_state.generated_pairs[i])
                                        new_selected.append(False)

                                st.session_state.generated_pairs = new_pairs
                                st.session_state.selected_pairs = new_selected
                                st.rerun()
                            else:
                                st.error("æ‰¹é‡è®­ç»ƒå¤±è´¥")

                # ç¼–è¾‘ç•Œé¢
                if 'editing_idx' in st.session_state:
                    st.markdown("---")
                    st.markdown("#### âœï¸ ç¼–è¾‘é—®é¢˜-SQLå¯¹")

                    editing_idx = st.session_state.editing_idx
                    original_question = st.session_state.editing_question
                    original_sql = st.session_state.editing_sql

                    new_question = st.text_area("ä¿®æ”¹é—®é¢˜", value=original_question, key="edit_question")
                    new_sql = st.text_area("ä¿®æ”¹SQL", value=original_sql, key="edit_sql")

                    col_edit1, col_edit2, col_edit3 = st.columns(3)

                    with col_edit1:
                        if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹", type="primary"):
                            if editing_idx < len(st.session_state.generated_pairs):
                                st.session_state.generated_pairs[editing_idx] = (new_question, new_sql)
                                del st.session_state.editing_idx
                                del st.session_state.editing_question
                                del st.session_state.editing_sql
                                st.success("ä¿®æ”¹å·²ä¿å­˜")
                                st.rerun()

                    with col_edit2:
                        if st.button("âŒ åˆ é™¤æ­¤å¯¹"):
                            if editing_idx < len(st.session_state.generated_pairs):
                                st.session_state.generated_pairs.pop(editing_idx)
                                if editing_idx < len(st.session_state.selected_pairs):
                                    st.session_state.selected_pairs.pop(editing_idx)
                                del st.session_state.editing_idx
                                del st.session_state.editing_question
                                del st.session_state.editing_sql
                                st.success("å·²åˆ é™¤")
                                st.rerun()

                    with col_edit3:
                        if st.button("â†©ï¸ å–æ¶ˆç¼–è¾‘"):
                            del st.session_state.editing_idx
                            del st.session_state.editing_question
                            del st.session_state.editing_sql
                            st.rerun()

            else:
                st.warning("è¯·å…ˆå‘ç°æ•°æ®åº“")

    elif train_type == "æ‰¹é‡è®­ç»ƒ":
        st.markdown("#### ğŸ“š æ‰¹é‡è®­ç»ƒ")
        st.caption("æ‰¹é‡å¯¼å…¥è®­ç»ƒæ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰")

        train_format = st.selectbox(
            "è®­ç»ƒæ•°æ®æ ¼å¼",
            ["é—®é¢˜-SQLå¯¹", "DDLåˆ—è¡¨", "æ–‡æ¡£åˆ—è¡¨"],
            key="batch_format"
        )

        if train_format == "é—®é¢˜-SQLå¯¹":
            example_data = [
                {
                    "question": "æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·ä¿¡æ¯",
                    "sql": "SELECT * FROM users"
                },
                {
                    "question": "ç»Ÿè®¡è®¢å•æ•°é‡",
                    "sql": "SELECT COUNT(*) FROM orders"
                }
            ]
        elif train_format == "DDLåˆ—è¡¨":
            example_data = [
                {
                    "ddl": "CREATE TABLE users (id INT, name VARCHAR(100))"
                }
            ]
        else:
            example_data = [
                {
                    "documentation": "ç”¨æˆ·è¡¨å­˜å‚¨ç”¨æˆ·åŸºæœ¬ä¿¡æ¯"
                }
            ]

        st.code(json.dumps(example_data, indent=2, ensure_ascii=False), language="json")

        batch_data = st.text_area(
            "æ‰¹é‡è®­ç»ƒæ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰",
            height=200,
            placeholder="ç²˜è´´JSONæ•°æ®..."
        )

        col1, col2 = st.columns(2)
        with col1:
            if st.button("éªŒè¯JSONæ ¼å¼", key="validate_json"):
                try:
                    data = json.loads(batch_data)
                    st.success(f"âœ… JSONæ ¼å¼æ­£ç¡®ï¼Œå…±{len(data)}æ¡è®°å½•")
                except Exception as e:
                    st.error(f"âŒ JSONæ ¼å¼é”™è¯¯: {str(e)}")

        with col2:
            if st.button("æ‰§è¡Œæ‰¹é‡è®­ç»ƒ", type="primary", key="batch_train"):
                if batch_data:
                    try:
                        data = json.loads(batch_data)
                        success_count = 0
                        total_count = len(data)

                        progress_bar = st.progress(0)
                        status_text = st.empty()

                        for i, item in enumerate(data):
                            status_text.text(f"æ­£åœ¨è®­ç»ƒç¬¬ {i+1}/{total_count} æ¡...")
                            progress_bar.progress((i + 1) / total_count)

                            if train_format == "é—®é¢˜-SQLå¯¹":
                                if 'question' in item and 'sql' in item:
                                    if training_manager.train_question_sql(item['question'], item['sql']):
                                        success_count += 1
                            elif train_format == "DDLåˆ—è¡¨":
                                if 'ddl' in item:
                                    if training_manager.train_ddl(item['ddl']):
                                        success_count += 1
                            elif train_format == "æ–‡æ¡£åˆ—è¡¨":
                                if 'documentation' in item:
                                    if training_manager.train_documentation(item['documentation']):
                                        success_count += 1

                        progress_bar.empty()
                        status_text.empty()

                        st.success(f"âœ… æ‰¹é‡è®­ç»ƒå®Œæˆï¼æˆåŠŸ: {success_count}/{total_count}")

                    except Exception as e:
                        st.error(f"æ‰¹é‡è®­ç»ƒå¤±è´¥: {str(e)}")
                else:
                    st.warning("è¯·è¾“å…¥æ‰¹é‡è®­ç»ƒæ•°æ®")

    elif train_type == "è®­ç»ƒå†å²":
        st.markdown("#### ğŸ“œ è®­ç»ƒå†å²")

        if training_manager:
            stats = training_manager.get_training_stats()

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»è®­ç»ƒæ¬¡æ•°", stats['total'])
            with col2:
                st.metric("è®­ç»ƒç±»å‹æ•°", len(stats['by_type']))
            with col3:
                if st.button("æ¸…ç©ºå†å²", type="secondary"):
                    training_manager.clear_history()
                    st.rerun()

            # æ˜¾ç¤ºè®­ç»ƒå†å²
            history = training_manager.get_train_history()
            if history:
                st.markdown("##### æœ€è¿‘è®­ç»ƒè®°å½•")
                for i, record in enumerate(reversed(history[-20:]), 1):
                    with st.expander(f"{i}. [{record['type']}] {record['timestamp'][:19]}"):
                        st.write(f"**å†…å®¹**: {record['content']}")
                        if record['metadata']:
                            st.write(f"**å…ƒæ•°æ®**: {record['metadata']}")
            else:
                st.info("æš‚æ— è®­ç»ƒå†å²")

    # å¿«é€Ÿè®­ç»ƒåŒºåŸŸ
    st.markdown("---")
    st.markdown("#### âš¡ å¿«é€Ÿè®­ç»ƒ")

    quick_train_col1, quick_train_col2, quick_train_col3 = st.columns(3)

    with quick_train_col1:
        if st.button("è®­ç»ƒå¸¸ç”¨æŸ¥è¯¢æ¨¡å¼", key="quick_patterns"):
            quick_patterns = [
                ("æŸ¥è¯¢è¡¨ç»“æ„", "DESCRIBE {table}"),
                ("æŸ¥çœ‹è¡¨æ•°æ®", "SELECT * FROM {table} LIMIT 10"),
                ("ç»Ÿè®¡è®°å½•æ•°", "SELECT COUNT(*) FROM {table}"),
                ("æŸ¥è¯¢å‰Næ¡", "SELECT * FROM {table} LIMIT {n}")
            ]

            for question, sql in quick_patterns:
                training_manager.train_question_sql(question, sql, {'type': 'quick_pattern'})

            st.success("âœ… å¸¸ç”¨æŸ¥è¯¢æ¨¡å¼è®­ç»ƒå®Œæˆ")

    with quick_train_col2:
        if st.button("è®­ç»ƒæ•°æ®åº“æœ¯è¯­", key="quick_terms"):
            terms = [
                "è¡¨æ˜¯æ•°æ®åº“ä¸­å­˜å‚¨æ•°æ®çš„åŸºæœ¬å•ä½",
                "å­—æ®µæ˜¯è¡¨ä¸­çš„åˆ—ï¼Œç”¨äºå­˜å‚¨ç‰¹å®šç±»å‹çš„æ•°æ®",
                "ä¸»é”®æ˜¯å”¯ä¸€æ ‡è¯†è¡¨ä¸­æ¯æ¡è®°å½•çš„å­—æ®µ",
                "å¤–é”®æ˜¯å…³è”ä¸¤ä¸ªè¡¨çš„å­—æ®µ"
            ]

            for term in terms:
                training_manager.train_documentation(term, {'type': 'terminology'})

            st.success("âœ… æ•°æ®åº“æœ¯è¯­è®­ç»ƒå®Œæˆ")

    with quick_train_col3:
        if db_info and 'databases' in db_info and st.button("è®­ç»ƒè¡¨åæŸ¥è¯¢", key="quick_table_names"):
            databases = db_info['databases']
            trained = 0

            for db_name, db_data in databases.items():
                tables = db_data.get('tables', [])[:5]  # æ¯ä¸ªæ•°æ®åº“è®­ç»ƒå‰5ä¸ªè¡¨
                for table in tables:
                    question = f"æŸ¥è¯¢{table}è¡¨"
                    sql = f"SELECT * FROM `{db_name}`.`{table}` LIMIT 10"
                    if training_manager.train_question_sql(question, sql, {'database': db_name, 'table': table}):
                        trained += 1

            st.success(f"âœ… è¡¨åæŸ¥è¯¢è®­ç»ƒå®Œæˆï¼Œå…±è®­ç»ƒ{trained}ä¸ªè¡¨")

# æ•°æ®åº“é€‰æ‹©ç»„ä»¶
def database_selector(db_info: Dict, current_priority_dbs: Set[str] = None):
    """æ•°æ®åº“é€‰æ‹©å™¨ç»„ä»¶"""
    if current_priority_dbs is None:
        current_priority_dbs = set()

    if not db_info or 'databases' not in db_info:
        st.warning("è¯·å…ˆå‘ç°æ•°æ®åº“")
        return current_priority_dbs

    st.markdown("### ğŸ¯ é€‰æ‹©ä¼˜å…ˆæ•°æ®åº“")
    st.info("é€‰æ‹©æ‚¨æœ€å¸¸æŸ¥è¯¢çš„æ•°æ®åº“ï¼Œç³»ç»Ÿä¼šä¼˜å…ˆåœ¨è¿™äº›æ•°æ®åº“ä¸­æŸ¥æ‰¾ç›¸å…³è¡¨")

    databases = list(db_info['databases'].keys())

    # ä½¿ç”¨å¤šé€‰æ¡†è®©ç”¨æˆ·é€‰æ‹©ä¼˜å…ˆæ•°æ®åº“
    selected_dbs = st.multiselect(
        "é€‰æ‹©ä¼˜å…ˆæ•°æ®åº“ï¼ˆå¯å¤šé€‰ï¼‰",
        databases,
        default=list(current_priority_dbs),
        format_func=lambda x: f"{x} ({db_info['databases'][x]['table_count']}ä¸ªè¡¨)",
        help="é€‰æ‹©åï¼Œç³»ç»Ÿä¼šä¼˜å…ˆåœ¨è¿™äº›æ•°æ®åº“ä¸­æŸ¥æ‰¾ç›¸å…³è¡¨"
    )

    # æ˜¾ç¤ºé€‰æ‹©çš„ç»Ÿè®¡
    if selected_dbs:
        total_tables = sum(db_info['databases'][db]['table_count'] for db in selected_dbs)
        st.success(f"å·²é€‰æ‹© {len(selected_dbs)} ä¸ªä¼˜å…ˆæ•°æ®åº“ï¼Œå…± {total_tables} ä¸ªè¡¨")

        # æ˜¾ç¤ºé€‰æ‹©çš„æ•°æ®åº“è¯¦æƒ…
        with st.expander("ğŸ“‹ æŸ¥çœ‹é€‰æ‹©çš„æ•°æ®åº“", expanded=True):
            for db in selected_dbs:
                db_data = db_info['databases'][db]
                st.markdown(f"""
                <div class="priority-database-card">
                <strong>{db}</strong> - {db_data['table_count']} ä¸ªè¡¨
                <span class="priority-badge">ä¼˜å…ˆ</span>
                </div>
                """, unsafe_allow_html=True)

                # æ˜¾ç¤ºå‰å‡ ä¸ªè¡¨
                for table in db_data['tables'][:3]:
                    col_count = db_data['tables_info'].get(table, {}).get('column_count', 0)
                    st.markdown(f"""
                    <div class="table-card">
                    &nbsp;&nbsp;ğŸ“Š {table} ({col_count}ä¸ªå­—æ®µ)
                    </div>
                    """, unsafe_allow_html=True)

                if db_data['table_count'] > 3:
                    st.caption(f"è¿˜æœ‰ {db_data['table_count']-3} ä¸ªè¡¨æœªæ˜¾ç¤º")

    return set(selected_dbs)

# ä¸»åº”ç”¨
def main():
    st.markdown('<h1 class="main-header">ğŸ¤– æ™ºèƒ½å¤šæ•°æ®åº“æŸ¥è¯¢åŠ©æ‰‹</h1>', unsafe_allow_html=True)
    st.markdown("è‡ªåŠ¨å‘ç°ã€å­¦ä¹ æ•°æ®åº“ç»“æ„ï¼Œæ™ºèƒ½ç”ŸæˆSQLæŸ¥è¯¢ï¼ˆæ”¯æŒä¼˜å…ˆæ•°æ®åº“ï¼‰")

    # åˆå§‹åŒ–
    vn = init_vanna()

    # åˆå§‹åŒ–session state
    if 'db_info' not in st.session_state:
        st.session_state.db_info = None
    if 'query_generator' not in st.session_state:
        st.session_state.query_generator = None
    if 'training_result' not in st.session_state:
        st.session_state.training_result = None
    if 'db_manager' not in st.session_state:
        st.session_state.db_manager = IntelligentDBAssistant()
    if 'priority_databases' not in st.session_state:
        st.session_state.priority_databases = set()

    db_manager = st.session_state.db_manager

    # ä¾§è¾¹æ  - æ•°æ®åº“è¿æ¥å’Œå‘ç°
    with st.sidebar:
        st.markdown("### ğŸ”Œ æ•°æ®åº“è¿æ¥")

        col1, col2 = st.columns(2)
        with col1:
            host = st.text_input("ä¸»æœºåœ°å€", value=os.getenv('DB_HOST', 'localhost'))
        with col2:
            port = st.number_input("ç«¯å£", value=int(os.getenv('DB_PORT', 3306)), min_value=1, max_value=65535)

        # ä¸€é”®å‘ç°æ‰€æœ‰æ•°æ®åº“
        if st.button("ğŸ” å‘ç°æ‰€æœ‰æ•°æ®åº“", type="primary", use_container_width=True):
            with st.spinner("æ­£åœ¨å‘ç°æ‰€æœ‰æ•°æ®åº“å’Œè¡¨..."):
                db_info = db_manager.discover_all_databases(host)

                if db_info and db_info.get('databases'):
                    st.session_state.db_info = db_info

                    # æ˜¾ç¤ºç»Ÿè®¡
                    st.success("âœ… å‘ç°å®Œæˆ!")

                    col_stat1, col_stat2 = st.columns(2)
                    with col_stat1:
                        st.metric("æ•°æ®åº“æ•°é‡", db_info['total_databases'])
                    with col_stat2:
                        st.metric("è¡¨æ€»æ•°é‡", db_info['total_tables'])
                else:
                    st.error("âŒ æœªå‘ç°æ•°æ®åº“")

        # å¦‚æœå·²å‘ç°æ•°æ®åº“ï¼Œæ˜¾ç¤ºæ•°æ®åº“é€‰æ‹©å™¨
        if st.session_state.db_info is not None:
            st.markdown("---")
            st.markdown("### ğŸ¯ ä¼˜å…ˆæ•°æ®åº“è®¾ç½®")

            # æ•°æ®åº“é€‰æ‹©å™¨
            selected_priority_dbs = database_selector(
                st.session_state.db_info,
                st.session_state.priority_databases
            )

            # ä¿å­˜é€‰æ‹©
            if st.button("ğŸ’¾ ä¿å­˜ä¼˜å…ˆæ•°æ®åº“è®¾ç½®", use_container_width=True):
                st.session_state.priority_databases = selected_priority_dbs
                st.success(f"å·²è®¾ç½® {len(selected_priority_dbs)} ä¸ªä¼˜å…ˆæ•°æ®åº“")

        # ä¸€é”®è®­ç»ƒæ‰€æœ‰æ•°æ®åº“
        if st.button("ğŸ¯ ä¸€é”®è®­ç»ƒæ‰€æœ‰æ•°æ®åº“", type="primary", use_container_width=True):
            if 'db_info' not in st.session_state or st.session_state.db_info is None:
                st.warning("è¯·å…ˆå‘ç°æ•°æ®åº“")
            elif not vn:
                st.error("Vanna åˆå§‹åŒ–å¤±è´¥")
            else:
                # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if st.session_state.query_generator is None:
                    st.session_state.query_generator = EnhancedSmartQueryGenerator(vn)

                query_generator = st.session_state.query_generator

                # è®¾ç½®ä¼˜å…ˆæ•°æ®åº“
                query_generator.set_priority_databases(st.session_state.priority_databases)

                with st.spinner("æ­£åœ¨è®­ç»ƒæ‰€æœ‰æ•°æ®åº“è¡¨ç»“æ„ï¼ˆä¼˜å…ˆæ•°æ®åº“ä¼šä¼˜å…ˆè®­ç»ƒï¼‰..."):
                    training_result = query_generator.train_all_databases(
                        db_manager, host, st.session_state.db_info
                    )

                st.session_state.training_result = training_result

                if training_result['success']:
                    # æ˜¾ç¤ºç»Ÿè®¡
                    priority_count = len(st.session_state.priority_databases)
                    normal_count = training_result['databases_trained'] - priority_count

                    st.success("âœ… è®­ç»ƒå®Œæˆ!")

                    col_train1, col_train2 = st.columns(2)
                    with col_train1:
                        st.metric("æ€»è®­ç»ƒæ•°æ®åº“", training_result['databases_trained'])
                        st.caption(f"ä¼˜å…ˆ: {priority_count} | æ™®é€š: {normal_count}")
                    with col_train2:
                        st.metric("è®­ç»ƒè¡¨", training_result['tables_trained'])

                    st.info(f"è®­ç»ƒè€—æ—¶: {training_result['training_time']:.1f}ç§’")

                    if training_result['errors']:
                        with st.expander("âš ï¸ æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                            for error in training_result['errors'][:5]:
                                st.error(error)
                else:
                    st.error("è®­ç»ƒå¤±è´¥")

        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        st.markdown("---")
        st.markdown("### ğŸ“Š å½“å‰çŠ¶æ€")

        if st.session_state.db_info is not None:
            info = st.session_state.db_info
            priority_count = len(st.session_state.priority_databases)
            st.write(f"**å·²å‘ç°**: {info['total_databases']}åº“/{info['total_tables']}è¡¨")
            st.write(f"**ä¼˜å…ˆåº“**: {priority_count}ä¸ª")
        else:
            st.write("**å·²å‘ç°**: æœªå‘ç°")
            st.write("**ä¼˜å…ˆåº“**: æœªè®¾ç½®")

        if (st.session_state.query_generator is not None and
            hasattr(st.session_state.query_generator, 'is_trained') and
            st.session_state.query_generator.is_trained):
            trainer = st.session_state.query_generator
            st.write(f"**å·²è®­ç»ƒ**: {len(trainer.trained_items)}ä¸ªè¡¨")
            st.write(f"**è®­ç»ƒçŠ¶æ€**: âœ… å·²è®­ç»ƒ")
        else:
            st.write("**å·²è®­ç»ƒ**: æœªè®­ç»ƒ")
            st.write("**è®­ç»ƒçŠ¶æ€**: âŒ æœªè®­ç»ƒ")

    # ä¸»ç•Œé¢ - åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ’¬ æ™ºèƒ½æŸ¥è¯¢", "ğŸ“ æ‰‹åŠ¨è®­ç»ƒ"])

    with tab1:
        # æ™ºèƒ½æŸ¥è¯¢ç•Œé¢
        st.markdown("### ğŸ’¬ æ™ºèƒ½æŸ¥è¯¢")

        # çŠ¶æ€æ˜¾ç¤º
        if (st.session_state.db_info is not None and
            st.session_state.query_generator is not None and
            hasattr(st.session_state.query_generator, 'is_trained') and
            st.session_state.query_generator.is_trained):

            # æ˜¾ç¤ºä¼˜å…ˆæ•°æ®åº“ä¿¡æ¯
            priority_count = len(st.session_state.priority_databases)
            if priority_count > 0:
                st.success(f"âœ… ç³»ç»Ÿå·²å°±ç»ªï¼å·²è®¾ç½® {priority_count} ä¸ªä¼˜å…ˆæ•°æ®åº“ï¼Œä¼šä¼˜å…ˆåœ¨è¿™äº›åº“ä¸­æŸ¥è¯¢")
            else:
                st.success("âœ… ç³»ç»Ÿå·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹æŸ¥è¯¢")
        elif st.session_state.db_info is not None:
            st.warning("âš ï¸ æ•°æ®åº“å·²å‘ç°ï¼Œè¯·å…ˆè¿›è¡Œè®­ç»ƒ")
        else:
            st.info("â„¹ï¸ è¯·å…ˆå‘ç°å¹¶è®­ç»ƒæ•°æ®åº“")

        # æŸ¥è¯¢è¾“å…¥
        st.markdown("#### ğŸ“ è¾“å…¥æ‚¨çš„æŸ¥è¯¢éœ€æ±‚")
        user_query = st.text_area(
            "ç”¨è‡ªç„¶è¯­è¨€æè¿°æ‚¨æƒ³è¦æŸ¥è¯¢ä»€ä¹ˆ",
            placeholder="ä¾‹å¦‚ï¼š\n1. å¸®æˆ‘æŸ¥ db_businessè¡¨çš„è¯¦æƒ…\n2. æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·çš„ä¿¡æ¯\n3. ç»Ÿè®¡è®¢å•æ•°é‡\n4. æŸ¥çœ‹ç”¨æˆ·è¡¨çš„å­—æ®µä¿¡æ¯",
            height=150,
            key="query_input"
        )

        # æŸ¥è¯¢é€‰é¡¹
        col_opt1, col_opt2, col_opt3 = st.columns(3)

        with col_opt1:
            action = st.radio("æ“ä½œ", ["ä»…ç”ŸæˆSQL", "ç”Ÿæˆå¹¶æ‰§è¡Œ"])
            limit_results = st.number_input("ç»“æœé™åˆ¶", min_value=1, max_value=10000, value=100)

        with col_opt2:
            show_relevant = st.checkbox("æ˜¾ç¤ºç›¸å…³è¡¨", value=True)
            auto_limit = st.checkbox("è‡ªåŠ¨æ·»åŠ LIMIT", value=True)
            prefer_priority = st.checkbox("ä¼˜å…ˆåœ¨ä¼˜å…ˆåº“æŸ¥è¯¢", value=True)

        with col_opt3:
            show_sql = st.checkbox("æ˜¾ç¤ºåŸå§‹SQL", value=True)
            explain_query = st.checkbox("è§£é‡ŠæŸ¥è¯¢", value=False)

        # æ‰§è¡ŒæŸ¥è¯¢æŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½æŸ¥è¯¢", type="primary", use_container_width=True) and user_query:
            if st.session_state.query_generator is None:
                st.error("è¯·å…ˆè®­ç»ƒæ•°æ®åº“")
                return

            if not hasattr(st.session_state.query_generator, 'is_trained') or not st.session_state.query_generator.is_trained:
                st.error("è¯·å…ˆè®­ç»ƒæ•°æ®åº“")
                return

            query_generator = st.session_state.query_generator
            db_info = st.session_state.db_info

            # æ­¥éª¤1: æ™ºèƒ½ç”ŸæˆæŸ¥è¯¢
            with st.spinner("ğŸ” æ­£åœ¨åˆ†ææŸ¥è¯¢éœ€æ±‚..."):
                query_result = query_generator.generate_smart_query(user_query, db_info)

            if not query_result['success']:
                st.error(f"ç”ŸæˆæŸ¥è¯¢å¤±è´¥: {query_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return

            # æ˜¾ç¤ºåŒ¹é…ç±»å‹
            match_type = query_result.get('match_type', 'unknown')
            if match_type == 'exact_table':
                st.success("ğŸ¯ å·²ç²¾ç¡®åŒ¹é…åˆ°è¡¨å!")
            elif match_type == 'vanna_generated':
                st.info("ğŸ¤– ä½¿ç”¨Vannaæ™ºèƒ½ç”Ÿæˆ")

            # æ˜¾ç¤ºç›¸å…³ä¿¡æ¯
            if show_relevant and query_result['relevant_info']['total_matches'] > 0:
                st.markdown("#### ğŸ¯ ç›¸å…³æ•°æ®åº“å’Œè¡¨")

                relevant_info = query_result['relevant_info']

                for db_name, db_data in relevant_info['databases'].items():
                    is_priority = db_data.get('priority', False)
                    priority_badge = " ğŸ¯" if is_priority else ""

                    with st.expander(f"ğŸ“ {db_name}{priority_badge} ({db_data['table_count']}ä¸ªç›¸å…³è¡¨)", expanded=is_priority):
                        for table_name, table_info in db_data['tables'].items():
                            st.write(f"**è¡¨: {table_name}**")
                            for match in table_info['matches'][:3]:
                                st.write(f"  â€¢ {match}")

            # æ˜¾ç¤ºç”Ÿæˆçš„SQL
            st.markdown("#### ğŸ“„ ç”Ÿæˆçš„SQL")

            sql = query_result['sql']

            # æ·»åŠ LIMITå­å¥
            if auto_limit and 'limit' not in sql.lower() and action == "ç”Ÿæˆå¹¶æ‰§è¡Œ":
                if sql.strip().endswith(';'):
                    sql = sql[:-1] + f" LIMIT {limit_results};"
                else:
                    sql += f" LIMIT {limit_results}"

            st.markdown(f'<div class="sql-container">{sql}</div>', unsafe_allow_html=True)

            # æ‰§è¡ŒæŸ¥è¯¢
            if action == "ç”Ÿæˆå¹¶æ‰§è¡Œ":
                with st.spinner("âš¡ æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢..."):
                    # ç¡®å®šæŸ¥è¯¢çš„æ•°æ®åº“
                    databases_to_query = query_result.get('used_databases', [])

                    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®åº“ï¼Œä»SQLä¸­æå–
                    if not databases_to_query:
                        # ä»SQLä¸­æå–æ•°æ®åº“å
                        pattern = r'`?(\w+)`?\.`?(\w+)`?'
                        matches = re.findall(pattern, sql)
                        for db_match, _ in matches:
                            if db_match in db_info.get('databases', {}):
                                databases_to_query.append(db_match)

                    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œåœ¨æ‰€æœ‰æ•°æ®åº“ä¸­å°è¯•
                    if not databases_to_query:
                        if prefer_priority and st.session_state.priority_databases:
                            databases_to_query = list(st.session_state.priority_databases)[:3]
                        else:
                            databases_to_query = list(db_info['databases'].keys())[:3]

                    all_results = {}
                    errors = []

                    for db in databases_to_query:
                        try:
                            results, error = db_manager.execute_query(host, db, sql)

                            if error:
                                errors.append(f"{db}: {error}")
                            elif results:
                                all_results[db] = pd.DataFrame(results)
                        except Exception as e:
                            errors.append(f"{db}: {str(e)}")

                    # æ˜¾ç¤ºç»“æœ
                    if all_results:
                        st.markdown("#### ğŸ“Š æŸ¥è¯¢ç»“æœ")

                        total_records = 0
                        priority_results = 0
                        normal_results = 0

                        # æ˜¾ç¤ºç»“æœ
                        for db, df in all_results.items():
                            total_records += len(df)

                            is_priority = db in st.session_state.priority_databases
                            if is_priority:
                                priority_results += len(df)
                            else:
                                normal_results += len(df)

                            priority_badge = " ğŸ¯" if is_priority else ""
                            with st.expander(f"âœ… æ•°æ®åº“: {db}{priority_badge} ({len(df)} æ¡è®°å½•)", expanded=is_priority):
                                st.dataframe(df, use_container_width=True)

                                # æ•°æ®ç»Ÿè®¡
                                col_stat1, col_stat2 = st.columns(2)
                                with col_stat1:
                                    st.write(f"**æ•°æ®ç»´åº¦**: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")
                                with col_stat2:
                                    st.write(f"**æ•°æ®å¤§å°**: {df.memory_usage(deep=True).sum() / 1024:.1f} KB")

                                # ä¸‹è½½æŒ‰é’®
                                csv = df.to_csv(index=False).encode('utf-8')
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                st.download_button(
                                    f"ğŸ“¥ ä¸‹è½½ {db} çš„æ•°æ®",
                                    csv,
                                    f"{db}_query_{timestamp}.csv",
                                    "text/csv",
                                    key=f"download_{db}"
                                )

                        # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
                        st.success(f"âœ… æ€»å…±åœ¨ {len(all_results)} ä¸ªæ•°æ®åº“ä¸­æ‰¾åˆ°äº† {total_records} æ¡è®°å½•")
                        if priority_results > 0:
                            st.info(f"ğŸ¯ å…¶ä¸­ {priority_results} æ¡æ¥è‡ªä¼˜å…ˆæ•°æ®åº“")

                    elif errors:
                        st.error("âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥")
                        with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                            for error in errors:
                                st.error(error)
                    else:
                        st.info("â„¹ï¸ æŸ¥è¯¢æˆåŠŸï¼Œä½†æœªæ‰¾åˆ°åŒ¹é…çš„æ•°æ®")

        # æ•°æ®åº“æ¦‚è§ˆ
        if st.session_state.db_info is not None:
            st.markdown("---")
            st.markdown("### ğŸ“‹ æ•°æ®åº“æ¦‚è§ˆ")

            info = st.session_state.db_info
            priority_dbs = st.session_state.priority_databases

            # æ˜¾ç¤ºç»Ÿè®¡
            col_overview1, col_overview2, col_overview3 = st.columns(3)
            with col_overview1:
                st.metric("æ€»æ•°æ®åº“", info['total_databases'])
                st.caption(f"ä¼˜å…ˆ: {len(priority_dbs)}")
            with col_overview2:
                st.metric("æ€»è¡¨æ•°", info['total_tables'])
            with col_overview3:
                avg_tables = info['total_tables'] / max(1, info['total_databases'])
                st.metric("å¹³å‡è¡¨æ•°", f"{avg_tables:.1f}")

            # æ˜¾ç¤ºæ•°æ®åº“åˆ—è¡¨
            with st.expander("ğŸ“ æŸ¥çœ‹æ‰€æœ‰æ•°æ®åº“", expanded=False):
                # å…ˆæ˜¾ç¤ºä¼˜å…ˆæ•°æ®åº“
                if priority_dbs:
                    st.markdown("#### ğŸ¯ ä¼˜å…ˆæ•°æ®åº“")
                    for db_name in priority_dbs:
                        if db_name in info['databases']:
                            db_data = info['databases'][db_name]
                            col_db1, col_db2 = st.columns([3, 1])
                            with col_db1:
                                st.markdown(f"**{db_name}** ğŸ¯")
                                table_list = ", ".join(db_data['tables'][:5])
                                if len(db_data['tables']) > 5:
                                    table_list += f" ç­‰ {db_data['table_count']} ä¸ªè¡¨"
                                st.write(f"è¡¨: {table_list}")
                            with col_db2:
                                st.write(f"{db_data['table_count']} ä¸ªè¡¨")

                # æ˜¾ç¤ºå…¶ä»–æ•°æ®åº“
                other_dbs = [db for db in info['databases'].keys() if db not in priority_dbs]
                if other_dbs:
                    st.markdown("#### ğŸ“Š å…¶ä»–æ•°æ®åº“")
                    for db_name in other_dbs[:10]:
                        db_data = info['databases'][db_name]
                        col_db1, col_db2 = st.columns([3, 1])
                        with col_db1:
                            st.markdown(f"**{db_name}**")
                            table_list = ", ".join(db_data['tables'][:3])
                            if len(db_data['tables']) > 3:
                                table_list += f" ç­‰ {db_data['table_count']} ä¸ªè¡¨"
                            st.write(f"è¡¨: {table_list}")
                        with col_db2:
                            st.write(f"{db_data['table_count']} ä¸ªè¡¨")

                    if len(other_dbs) > 10:
                        st.info(f"è¿˜æœ‰ {len(other_dbs)-10} ä¸ªæ•°æ®åº“æœªæ˜¾ç¤º")

    with tab2:
        # æ‰‹åŠ¨è®­ç»ƒç•Œé¢
        if vn and st.session_state.db_info is not None:
            # åˆ›å»ºæˆ–è·å–è®­ç»ƒç®¡ç†å™¨
            if st.session_state.query_generator is not None:
                training_manager = st.session_state.query_generator.training_manager
            else:
                training_manager = VannaTrainingManager(vn)

            show_manual_training_interface(
                training_manager,
                db_manager,
                host,
                st.session_state.db_info
            )
        else:
            st.warning("è¯·å…ˆåˆå§‹åŒ–Vannaå¹¶å‘ç°æ•°æ®åº“")

            if not vn:
                st.error("Vannaæœªåˆå§‹åŒ–")
            if st.session_state.db_info is None:
                st.error("æ•°æ®åº“æœªå‘ç°")

# è¿è¡Œåº”ç”¨
if __name__ == "__main__":
    main()